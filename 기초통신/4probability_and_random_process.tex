\chapter{기초 확률변수론과 랜덤프로세스}
통신을 배우는데 확률은 왜 배워야 할까? 통신은 정보를 주고받는 것이고, 정보는 새로운 것이라고 했다.
그리고 새로운 것은 알지 못하는 것이다. 알지 못하는 것에 대해서는 확률적으로 추정할 수밖에 없다.
또한 확률이 낮은 사건에 대한 정보는 가치가 크다.
이 장에서는 먼저 확률에 대해 알아보고, 다음으로 확률변수가 시간축으로 늘어서는, 즉 시간의 함수인 랜덤프로세스(확률과정)에 대해 알아보겠다.

\section{확률변수론}
확률변수란 것은 변수는 변수인데 확률에 따라 값이 정해지는 변수라는 뜻이다. 따라서 확률변수를 이해하기 위해서는 확률부터 알아야 한다.
\subsection{확률}
\subsubsection{용어 정의와 중요한 법칙과 정리들}
확률은 집합론에 기반한다. 어떤 사건 $A$의 확률이란 모든 시행의 결과들 개수 대비 이 사건 $A$에 해당하는 시행 결과들의 개수의 비율이다.
그리고 이 결과들을 집합으로 나타내며, 이 때 각 집합의 이름은 사건 이름과 같게 한다.
또한, 시행의 모든 결과들을 모은 집합 $S$를 샘플 공간이라고 부르며, 이 시행과 관련되어 있는 모든 사건 $A$의 결과들의 집합은 $S$의 부분집합이다.
이로써 어떤 사건 $A$에 대해 이 사건이 일어날 확률을 $P(A)$라고 쓸 수 있으며, $P(\cdot)$ 안에 들어가는 인자를 집합으로 취급할 수 있다.
그리고 집합 $A$의 원소의 개수를 $n(A)$라고 쓸 때, 확률의 정의상 $P(A)=n(A)/n(S)$가 됨을 알 수 있다,
예를 들어 주사위를 던져서 윗면을 확인하는 시행이 있다고 하자. 이 시행의 모든 결과들을 나타내면 $\{1,2,3,4,5,6\}$이 된다.
그리고, 짝수가 나오는 사건을 생각하자. 이 사건을 집합으로 나타내면 $\{2,4,6\}$이 된다.
따라서 $P(짝수)=$(짝수 사건 시행 결과 개수)/(전체 시행 결과 개수)=(짝수 사건 결과 집합 원소 개수)/(전체 시행 결과 집합 원소 개수)=$3/6=1/2$인 것이다.
\paragraph{상호 배제}
만약 두 사건 $A,B$이 공통적인 결과를 하나도 갖지 않는다면 상호 배제라고 한다.
이런 경우, 집합 $A$와 집합 $B$의 공통 원소가 하나도 없으므로 $A$ 또는 $B$가 일어날 사건의 결과 집합은 $A\cup B=A+B$이다.
따라서 $P(A\cup B)=P(A)+P(B)$이다. 또한, $A$와 $B$를 동시에 만족하는 결과가 나올 확률은 없다. 즉 $P(A\cap B)=0$이다.
\paragraph{결합 확률}
만약 $A$와 $B$가 상호 배제인 사건이 아니라면 어떨까? 당연히 $P(A\cap B)\neq 0$이다. 추후에 결합 확률은 중요하게 다뤄질 것이다.
\paragraph{조건부 확률}
조건부 확률은 특히 이해하기 어려운 확률인 것 같다. 이럴 땐 정의로 돌아가자.
어떤 사건 $A$가 일어날 확률은 샘플 공간 $S$의 원소 개수 대비 $A$의 원소 개수의 비율이었다.
그렇다면, 어떤 사건 $B$가 일어났을 때 사건 $A$가 일어날 확률은 어떻게 구할까?
다시 말해서, 주사위의 눈이 3 이하가 나오는 사건 $T$가 있다고 하자. $P(T)$의 값은 $n(F)/n(S)=3/6$이었다.
그런데, 주사위의 눈이 짝수가 나왔을 때 사건 $T$가 일어날 확률 즉 이 눈이 3 이하일 확률은 어떻게 구할 수 있을까?
이미 주사위의 눈은 짝수가 나왔다. 즉 샘플 공간이 $E=\{1,2,3,4,5,6\}$이 아니라 $\{2,4,6\}$이 된 것이다.
이 새로운 샘플 공간 $E$ 내에 있는 사건 $A$의 결과는 2로 1개이다.
따라서 주사위의 눈이 짝수가 나왔을 때 이 눈이 3 이하일 확률은 $1/3$이 되는 것이다.
이를 일반화하면 사건 $B$가 일어났음이 주어졌을 때 사건 $A$의 확률은 $P(A\vert B)$라 쓰며 다음과 같이 계산된다.
\begin{equation}
    P(A\vert B)=P(A \cap B)/P(B)\label{eqn:conditional probability}
\end{equation}
만약 $A$와 $B$가 상호 배제라면 $P(A \cap B)=0$이므로 $P(A\vert B)$ 또한 0이 된다.
그리고 이 식 \ref{eqn:conditional probability}\은 중요한 의미를 담고 있다. 양변에 $P(B)$를 곱하면
\begin{equation}
    P(A\cap B)=P(A\vert B)P(B)\label{eqn:A and B representated by conditional probability}
\end{equation}
라는 것이다. 이는 나중에 유용하게 이용될 것이니 잘 기억해 두자.
\par
조건부 확률 어렵게 생각할 것 없다. 그냥 $\vert$ 오른쪽의 사건이 전체집합 즉 샘플 공간이 되는 것으로 생각하면 끝이다. 이래서 정의가 중요하다.
\paragraph{총 확률 법칙}
사건들 $B_n(n=1,2,3,\cdots ,N)$들이 상호 배제이고 이 $B_n$들 모두를 모으면 샘플 공간이 된다고 하자.
이 때 어떤 사건 $A$가 이 샘플 공간의 부분집합을 결과 집합으로 가진다고 한다면 다음이 성립한다.
\begin{equation}
    P(A)=\sum_{n=1}^{N} P(A\cap B_n)
\end{equation}
식 \ref{eqn:A and B representated by conditional probability}\을 이용하면 다음과 같이 변형된다.
\begin{equation}
    P(A)=\sum_{n=1}^{N} P(A\vert B_n)P(B_n)
\end{equation}
왜 그런지는 \figurename~\ref{fig:total prob}\을 보면 알 수 있을 것이다.
\begin{figure}[!hpb]
    \centering
    \image[height=5cm]{total prob.png}
    \caption{총 확률 법칙의 그림 표현}\label{fig:total prob}
\end{figure}
\paragraph{베이즈 정리}
베이즈 정리는 통신에서 매우매우 중요하다. 이것이 디지털 통신의 핵심 원리이기 때문이다.
식 자체는 간단하다. 그냥 식 \ref{eqn:conditional probability}의 변형이 다이다. 이 식을 다음과 같이 변형할 수 있다.
\begin{IEEEeqnarray*}{rCl}
    P(A\vert B)&=&\frac{P(A\cap B)}{P(B)}\\
    &=&\frac{P(B\vert A)P(A)}{P(B)}\label{eqn:bayes' thm}
\end{IEEEeqnarray*}
중요한 것은 그 의미이다. 두 사건 $A,B$의 발생 확률과 한 사건이 발생했을 때 다른 사건이 발생할 조건부 확률을 안다면, 사건 둘을 바꾼 조건부 확률도 알 수 있다는 것이다.
\par
이를 통신에 응용해보자. 사람 A와 B가 있을 때, A가 B에게 메시지를 보낸다고 하자. 이 때 B가 어떤 메시지를 받았는데 이것이 A가 보낸 메시지가 오류 없이 전달되었을 확률은 어떻게 구할까?
사전에 어떤 메시지가 발생할 확률, 그리고 그 메시지 발생했을 때 제대로 전달될 확률과 오류가 발생할 확률을 알고 있다면, 반대로 어떤 메시지를 받았을 때 그 메시지가 의도한 메시지일 확률을 추정할 수 있는 것이다.
\paragraph{독립사건}
사건 $A$와 $B$가 독립이라는 의미는 사건 $A$가 일어났건 말건 $B$가 일어날 확률은 변함이 없음을 뜻한다. 즉
\begin{equation}
    P(A\vert B)=P(A) \Longleftrightarrow \frac{P(A\cap B)}{P(B)}=P(A) \Longleftrightarrow P(A\cap B)=P(A)P(B)\label{eqn:independent events}
\end{equation}
이다. 이를 일반화하면
\begin{equation}
    P(A_1\cap A_2 \cap \cdots \cap A_N)=P(A_1)P(A_2)\cdots P(A_N)
\end{equation}
이 된다.
\subsection{확률변수}
지금까지는 어떤 사건에 대해서 실제 결과에 대해서 생각했다. 즉 주사위의 눈이 3이 나왔다는 것은 숫자 3을 뜻한다기보다는 기호 $\cdots $가 나왔다는 것으로 보자.
더 와닿는 예로는 동전을 던지는 사건이 있겠다. 이 사건의 시행 결과는 앞 또는 뒤이므로 이 샘플 공간은 {앞,뒤}가 될 것이다.
반드시 그렇다고는 못 하겠지만, 어떤 대상을 수학적으로 해석하고 다루기 위해서는 그 대상을 숫자로 바꿔서 연산을 할 수 있으면 좋을 것 같다.
혹시 수학의 불완전성 정리에 대해서 들어보았는가? 그 핵심 아이디어는 논리 기호를 숫자로 대응시켜서 연산법칙을 적용하는 것이다.
마찬가지로, 어떤 시행의 샘플 공간의 원소들을 실수에 대응시켜보자. 그러기 위해선 샘플 공간의 원소들과 대응되는 실수 간의 규칙 혹은 관계가 있을 것이다.
즉, 샘플 공간의 각 원소들에서 숫자로 가는 함수를 생각하자는 것이다. 이 함수를 바로-이름은 변수지만-확률변수라고 한다.
동전 던지기를 다시 생각해보자. 앞면을 1에, 뒷면을 0에 대응시키는 확률변수 X를 생각할 수 있다. 이렇게 함으로써 연산들을 통해서 이 사건에 대한 여러 정보들을 얻어낼 수 있는 것이다.
이제부터는 실제 사건의 결과 대신 그에 대응하는 확률변수값들에 대해서 생각하자.
\paragraph{확률변수의 조건}
확률변수는 다음 조건들을 만족해야한다.
\begin{itemize}
    \item 집합 $\{X\text{의 값}\vert X\leqq x\}$은 모든 실수 $x$에 대해 하나의 사건에 대응된다. 즉 $P(X\leqq x)$은 이 집합의 각 원소에 대응되는 사건들의 확률들을 다 더한 값이다.
    \item $P(\pm  \infty)=0$이다. 확률변수가 가질 수 있는 값은 유한한 실수라는 뜻이다.
\end{itemize}
또한 확률변수는 연속적인 값을 가지느냐 이산적인 값을 가지느냐에 따라 나뉜다. 혹은 어디서는 이산적이다가 어디서는 연속적일 수도 있다.
\subsubsection{누적 분포 함수}
누적 분포 함수(Cumulative Distribution Function;CDF)\index{누적 분포 함수}\index{CDF}란 어떤 확률변수 $X$에 대해서 이 확률변수값이 $x$ 이하가 될 확률을 의미하고, $F_X(x)$로 표기한다.
즉
\begin{equation}
    F_X(x)=P(X\leqq x)\label{eqn:def of cdf}
\end{equation}
이다.
\paragraph{누적 분포 함수의 성질}
누적 분포 함수의 성질은 다음과 같다. 당연한 것들이다.
\begin{itemize}
    \item $0\leqq F_X(x)\leqq 1$
    \item $F_X(-\infty)=0$, $F_X(\infty)=1$: 확률변수가 갖는 값의 범위는 유한하다.
    \item $x_1\leqq x_2$이면 $F_X(x_1)\leqq F_X(x_2)$
    \item $P(x_1<x\leqq x_2)=P(x\leqq x_2)-P(x_1<x)=F_X(x_2)-F_X(x_1)$
    \item $F_X(x^+)=F_X(x)$: $x$보다 아주 살짝 큰 값인 $x^+$와 $x$ 사이에 $X$가 분포할 확률은 0이란 뜻이다.
\end{itemize}
\subsubsection{확률 밀도 함수}
확률 밀도 함수(Probability Density Function;PDF)\index{확률 밀도 함수}\index{PDF}란 적분하였을 때 누적 분포 함수가 되는 함수를 말한다. 즉
\begin{equation}
    F_X(x)=\int_{-\infty}^{x}f_X(x)dx\label{eqn:def of pdf}
\end{equation}
이 PDF의 정의이다.
디랙 델타 함수를 사용하면 이산확률변수에 대해서도 쓸 수 있긴 하지만 PDF는 연속확률변수에 대한 함수이다. 그 이유는, 연속확률변수는 특정 지점에서의 확률값이 0이기 때문이다.
연속확률변수가 가질 수 있는 값은 무한히 많은 점들로 이루어진 범위로 주어지므로 분모는 무한대인데 비해 특정 점 한개는 말 그대로 1개이다. 따라서 확률이 $1\infty=0$이 되는 것이다(엄밀한 설명은 아니다).
그래서 확률값 자체보다는 밀도를 생각하여 쓰는 것이다. 식 \ref{eqn:def of pdf}의 양변을 미분하여 보라. 확률값인 $F_X(x)$를 구간 $dx$로 나누고 있지 않은가?
즉 확률밀도함수란 것은 실수축을 따라 각 지점에서의 밀도값을 의미하게 되는 것이다.
\paragraph{확률 밀도 함수의 성질}
확률 밀도 함수의 성질은 다음과 같다. 마찬가지로 당연한 것들이다.
\begin{itemize}
    \item $f_X(x)\geqq 0$
    \item $\int_{-\infty}^{\infty}f_X(x)dx=F_X(\infty)-F_X(-\infty)=1$
    \item $P(x_1<X\leqq x_2)=F_X(x_2)-F_X(x_1)=\int_{x_1}^{x_2}f_X(x)dx$
\end{itemize}
\subsection{확률변수에 대한 연산}
기댓값(평균), 분산, 표준편차 같은 용어는 이미 알고 있을 것이다. 이들은 이들 값을 뽑는 연산자를 확률변수에 적용하여 구한 것이다. 근데 사실 다 기댓값들이다.
그럼 기댓값이 무엇인지부터 살펴보자.
\subsubsection{기댓값}\label{기댓값}
기댓값은 이미 고등학교 때 배워서 알고 있을 것이다. 여기선 좀 다른 측면으로 생각해보자.
주사위를 던지는 시행을 아주 많이 한다고 해 보자. 그리고 확률변수 $X$를 주사위 눈의 값을 그대로 실수값으로 대응시키는, 즉 1을 1로 대응시키는 확률변수라고 하자.
아주 많은 횟수 $n$만큼 시행을 한다면, 이 시행의 결과에 대한 확률변수 값을 다 더한 값은 얼마가 될까? 1,2,3,4,5,6 각각 $n/6$만큼 나올 것이므로, 1부터 6까지 각각의 값에 $n/6$을 곱해서 다 더하면 된다.
즉 $(1+2+3+4+5+6)n/6=21n/6$이 되는 것이다.
한편, 요상한 주사위가 있어서 눈의 값이 $m$ 하나만 있다고 하자. 여기서도 마찬가지로 눈의 값 $m$을 실수 $m$으로 대응시키는 확률변수가 있다 하자. 이 주사위를 던지면 당연히 $m$밖에 나오지 않는다. 즉 이 주사위를 $n$회 던졌을 때 나오는 값에 대한 확률변수 값의 합을 구하면 $m\cdot n$이다.
이 두 주사위의 합이 같다면 어떻게 될까? 식을 세워서 풀어보면 $21n/6 = m\cdot n$이므로 $m=21/6=7/2$가 되면 이 조건을 만족한다. 이 값 $m$을 바로 산술평균이라 하며, 확률에서는 기댓값이라 부른다.
일반화하자면, 어떤 확률변수 $X$의 기댓값이란 이 $X$가 가질 수 있는 값들을 여러 번, 아주 많이 더해볼 때, 같은 횟수로 하나의 값을 계속 다 더해서(=이 하나의 값에 횟수를 곱해서) 둘이 같아지게 하는 그 특정값이다.
이 때 양변을 횟수로 나눠준다면 위 문장의 왼쪽은 각 값과 그 값이 나타나는 비율 즉 확률을 곱해서 다 더하는 값이 되고, 오른쪽은 그냥 기댓값이 된다.
수식으로 정의하면 다음과 같다.
\begin{equation}
    E[X]=m_X=\overline{X}= \sum_{i=1}^{N}x_iP(X=x_i)
\end{equation}
만약 $X$가 연속확률변수라면 $X=x$에 대해 그 주변의 미소구간에서의 확률값은 $f_X(x)dx$가 될 것이고, 위 식의 $\sum$을 $\int$로 바꾸면 다음과 같다.
\begin{equation}
    E[X]=\int_{-\infty}^{\infty}xf_X(x)dx
\end{equation}
앞서 언급했듯 델타 함수를 이용하여 PDF를 표현한다면 이산확률변수는 연속확률변수의 특수한 케이스로 취급할 수 있으므로 이제부터는 웬만하면 연속확률변수 버전을 사용하겠다.

\paragraph{분산}
분산 또한 기댓값의 일종이다. 평균으로부터 $X$의 분포가 얼마나 흩어져 있는지를 흩어진 정도의 제곱을 평균함으로써 나타내는 것이기 때문이다.
수식으로 쓰자면 아래와 같다.
\begin{equation}
    V[X]=\sigma^2=E[(X-\overline{X})^2]
\end{equation}

\subsection{다변량 확률변수}
한 번에 하나의 확률변수가 아닌 두 개 이상의 확률변수를 생각할 수도 있을 것이다. 이처럼 같은 샘플 공간에서 정의되는 여러 확률변수들을 묶은 것을 다변량 확률변수라고 한다.
여기서는 2개의 확률변수 $X$, $Y$를 묶은 이변량 확률변수 $(X,Y)$에 대해서 생각해보자.
\subsubsection{결합 CDF(Joint CDF)}
$X$와 $Y$에 대한 결합 CDF는 다음과 같다.
\begin{equation}
    F_{XY}(x,y)=P[X\leqq x , Y\leqq y]
\end{equation}
여기서 쉼표는 '그리고'를 의미한다.
\paragraph{독립인 경우의 결합 CDF}
만약 $X$와 $Y$가 독립이라면
\begin{equation}
    F_{XY}(x,y)=F_X(x)F_Y(y)
\end{equation}
이다.
\paragraph{한계 CDF}
한계 CDF란 용어는 Marginal CDF를 내 나름대로 번역한 것이다. Marginal은 경계의, 주변의 등의 의미가 있는데, 이들보다는 한국어로 한계비용이라 번역되는 marginal cost의 marginal과 비슷하다고 생각되어서 이를 선택했다.
한계 CDF란 다변량 확률변수의 결합 CDF로부터 나온 하나의 확률변수에 대한 CDF이다. 수식으로 쓰면 다음과 같다.
\begin{eqnarray}
    F_X(x)=F_{XY}(x,\infty)\nonumber\\
    F_Y(y)=F_{XY}(\infty,y)
\end{eqnarray}
이 의미는 관심있는 확률변수 외의 다른 확률변수에 대해서는 확률을 다 더해서 제거해 버린 것이라고 볼 수 있다. 따라서 관심있는 확률변수에 대한 정보만이 남는 것이다.
\subsubsection{결합 PDF(Joint PDF)}
결합 CDF를 생각할 수 있다면 결합 PDF도 생각할 수 있을 것이다. 기존 CDF와 PDF의 관계처럼 아래와 같이 정의된다.
\begin{equation}
    f_{XY}(x,y)=\frac{\partial^2}{\partial x \partial y} F_{XY}(x,y) \Longleftrightarrow F_{XY}(x,y)=\int_{-\infty}^{x} \int_{-\infty}^{y}f_{XY}(u,v)dudv 
\end{equation}
이 결합 PDF를 이용하면 다음과 같은 수식이 성립함을 알 수 있다.
\begin{equation}
    P[x_1<X \leqq x_2, y_1 < Y \leqq y_2]=\int_{x_1}^{x_2}\int_{y_1}^{y_2}f_{XY}(x,y)dydx
\end{equation}
\paragraph{한계 PDF}
한계 PDF는 아래와 같이 된다.
\begin{equation}
    f_X(x)=\int_{-\infty}^{\infty}f_{XY}(x,y)dy
\end{equation}
\paragraph{독립인 경우의 결합 PDF}
만약 $X$와 $Y$가 독립이면
\begin{equation}
    f_{XY}(x,y)=f_X(x)f_Y(y)
\end{equation}
이다.

\subsubsection{조건부 분포}
\paragraph{조건부 PDF}
조건부 PDF는 다음과 같다.
\begin{equation}
    f_{\left.X\right\vert Y}(\left.x\right\vert y)=\frac{f_{XY}(x,y)}{f_Y(y)}
\end{equation}
만약 $X$,$Y$가 독립이라면 다음과 같다.
\begin{equation}
    f_{\left.X\right\vert Y}(\left.x\right\vert y)=f_X(x)
\end{equation}
\paragraph{조건부 CDF}
조건부 CDF는 다음과 같다.
\begin{IEEEeqnarray}{rCl}
    F_{\left. X \right\vert Y}(\left. x \right\vert y)&=&P[\left. X\leqq x\right\vert Y=y]\nonumber\\
    &=&\int_{u\leqq x}f_{\left. X\right\vert Y}(\left. u\right\vert y)du
\end{IEEEeqnarray}
\paragraph{조건부 평균}
조건부 평균은 다음과 같다.
\begin{equation}
    m_{\left.X\right\vert Y}=E[X|Y=y]=\int_{x}xf_{X|Y}(x|y)dx
\end{equation}
\paragraph{조건부 분산}
조건부 분산은 다음과 같다.
\begin{IEEEeqnarray*}{rCl}
    \sigma ^2 _{X|Y}&=&E\left[ \left. (X-m_{X|Y})^2\right| Y=y\right]\\
    &=&\int_{x}(x-m_{X|Y})^2f_{X|Y}(x|y)dx\\
    &=&E\left[ \left. X^2 \right| Y=y \right]-m^2_{X|Y}\IEEEyesnumber
\end{IEEEeqnarray*}

\subsubsection{공분산과 결합계수}
$X$와 $Y$의 공분산은 다음과 같이 정의된다.
\begin{IEEEeqnarray*}{rCl}
    Cov[X,Y]&=&\sigma_{XY}=E[(X-m_X)(Y-m_y)]\\
    &=&E[XY-m_XY-m_YX+m_Xm_Y]\\
    &=&E[XY]-m_XE[Y]-m_YE[X]+m_Xm_Y\\
    &=&E[XY]-m_Xm_Y-m_Xm_Y+m_Xm_Y\\
    &=&E[XY]-m_Xm_Y\IEEEyesnumber
\end{IEEEeqnarray*}
만약 $Cov[X,Y]=0$이라면 이 둘은 상관관계가 없다(uncorrelated)라고 한다.
$X$,$Y$가 독립이라면 $E[XY]=E[X]E[Y]=m_Xm_Y$이므로 $Cov[X,Y]=0$이 되어 독립이라면 상관관계가 없다. 하지만 상관관계가 없다(공분산이 0이다)라고 해서 독립이라고 할 수는 없다.
\paragraph{결합계수}
두 확률변수의 상관관계가 얼마나 강한지 나타내는 값을 결합계수라고 한다.
공분산은 확률변수의 값 자체가 큰 경우 상관관계에 상관없이 큰 값이 나타날 수 있기 때문에, 공분산을 각각의 표준편차로 나누어(그래야 단위가 맞다) 정규화를 시킨다.
이렇게 하면 결합계수는 -1과 1 사이의 값이 되어 상관의 정도를 알 수 있게 된다.
\begin{equation}
    \rho_{XY}=\frac{Cov[X,y]}{\sqrt{Var(X)Var(Y)} }=\frac{\sigma_{XY}}{\sigma_X\sigma_Y}
\end{equation}
\subsection{$Y=g(X)$ 형태의 확률변수}
어떤 확률변수 Y가 다른 확률변수 X로부터 정의될 수 있다. 가령, X가 주사위의 눈 값에 대응되는 확률변수라면, 이를 제곱한 $Y=X^N$라는 확률변수 $Y$도 정의될 수 있을 것이다. 이 $Y$에 대해 알아보자.
\subsubsection{확률변수에 대한 함수의 기댓값}
$g(\cdot)$이란 함수의 출력은 $X$의 값에 의존하므로, 각 $X=x$ 값에 대한 함수의 출력 $y=g(x)$는 그 근원인 $X$의 확률대로 나타날 것이다.
따라서 그냥 $X$에 대해서와 마찬가지로 $Y$를 $X$에 대해서 쓰고 $X$의 각 확률을 곱해서 더하면 된다. 즉
\begin{equation}
    E[Y]=E[g(X)]=\int_{-\infty}^{\infty}g(x)f_X(x)dx
\end{equation}
이다.
\subsubsection{$Y=g(X)$의 CDF와 PDF}
앞에서  





\section{랜덤 프로세스}